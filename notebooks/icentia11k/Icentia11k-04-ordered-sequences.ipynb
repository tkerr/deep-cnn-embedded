{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d9dc73",
   "metadata": {},
   "source": [
    "# Icentia11k-04-ordered-sequences.ipynb\n",
    "Create CSV files of uniformly ordered sequences for an even distribution of patients, segments and rhythms.  \n",
    "Run Icentia11k-02-find-sequences.ipynb to create rhythm CSV files.  \n",
    "Run Icentia11k-03-select-sequences.ipynb to create sequence CSV files from the rhythm CSV files.  \n",
    "Run this notebook to create ordered versions of the CSV files per rhythm type from the sequence CSV files.  \n",
    "See https://physionet.org/content/icentia11k-continuous-ecg/1.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def2559",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d7ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup.\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from time import localtime, strftime\n",
    "import numpy as np\n",
    "\n",
    "import fileutils as fu\n",
    "import icentia11k as ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed24a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global objects.\n",
    "seq_file_pat = re.compile(ic.SEQUENCES_FILE_RE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f79bc4",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a94a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file into a memory list.\n",
    "def load_file(file_name):\n",
    "    file_list = []\n",
    "    with fu.open_file(file_name) as fd:\n",
    "        for line in fd:\n",
    "            file_list.append(line)\n",
    "    fu.close_file(fd)\n",
    "    return file_list\n",
    "\n",
    "# Parse a file line and return PID and SID as integers.\n",
    "def get_pid_sid(line):\n",
    "    (pid, sid, rtype, start, length) = line.strip().split(',')\n",
    "    return int(pid[1:]), int(sid[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c38da1",
   "metadata": {},
   "source": [
    "### 1. Get a list of all sequence files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e430685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_file_list = []\n",
    "for (dirpath, dirs, files) in os.walk(ic.LOCAL_DATA_PATH):\n",
    "    for file in files:\n",
    "        if seq_file_pat.match(file):\n",
    "            seq_file_list.append(os.path.join(dirpath, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24eaa1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequence files: 439\n",
      "[ 'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00000_p00099_AFIB.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00000_p00099_AFL.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00000_p00099_N.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00000_p00099_Q.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00100_p00199_AFIB.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00100_p00199_AFL.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00100_p00199_N.csv',\n",
      "  'E:/Data/Icentia11k/data\\\\p00\\\\sequences_p00100_p00199_Q.csv']\n"
     ]
    }
   ],
   "source": [
    "print('Total sequence files: {}'.format(len(seq_file_list)))\n",
    "ic.pprint(seq_file_list[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2b565",
   "metadata": {},
   "source": [
    "### 2. Create an ordered version of each sequence file  \n",
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a540bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the next PID in the supplied list given the current PID and list index.\n",
    "def next_pid_in_list(seq_list, index, curr_pid):\n",
    "    list_len = len(seq_list)\n",
    "    pid, sid = get_pid_sid(seq_list[index])\n",
    "    while (pid <= curr_pid):\n",
    "        index += 1\n",
    "        if (index >= list_len):\n",
    "            # Roll over to beginning of list.\n",
    "            index = 0\n",
    "            pid, sid = get_pid_sid(seq_list[index])\n",
    "            break\n",
    "        pid, sid = get_pid_sid(seq_list[index])\n",
    "    return pid, sid, index\n",
    "\n",
    "# Get the next SID in the supplied list for the current PID, SID and list index.\n",
    "def next_sid_in_list(seq_list, index_in, curr_pid, curr_sid):\n",
    "    list_len = len(seq_list)\n",
    "    index = index_in\n",
    "    found = False\n",
    "    pid, sid = get_pid_sid(seq_list[index])\n",
    "    while not found:\n",
    "        if (pid == curr_pid):\n",
    "            if (sid > curr_sid):\n",
    "                found = True\n",
    "            else:\n",
    "                index += 1\n",
    "                if (index < list_len):\n",
    "                    # Get next PID, SID combination\n",
    "                    pid, sid = get_pid_sid(seq_list[index])\n",
    "                else:\n",
    "                    # End of list. Roll over to beginning and exit.\n",
    "                    index = index_in\n",
    "                    pid, sid = get_pid_sid(seq_list[index])\n",
    "                    found = True\n",
    "        else:\n",
    "            # Ran out of SIDs for this PID. Roll over to beginning and exit.\n",
    "            index = index_in\n",
    "            pid, sid = get_pid_sid(seq_list[index])\n",
    "            found = True\n",
    "    return pid, sid, index\n",
    "\n",
    "# Create an ordered file from a single sequence file.\n",
    "def order_file(seq_file):\n",
    "    \n",
    "    # Create the ordered file name from the sequences file name.\n",
    "    seq_range = seq_file_pat.search(seq_file).group(1)\n",
    "    ordered_dir = os.path.dirname(os.path.abspath(seq_file))\n",
    "    ordered_file = os.path.join(ordered_dir, 'ordered_{}.csv'.format(seq_range))\n",
    "    ofd = fu.open_file(ordered_file, 'w')\n",
    "\n",
    "    max_pids = 100  # PIDs range from xxx00 to xxx99 in each sequences file\n",
    "    sid_list = [-1 for i in range(max_pids)]\n",
    "    seq_list = load_file(seq_file)\n",
    "    \n",
    "    # Get the first PID and SID.\n",
    "    index = 0\n",
    "    pid, sid = get_pid_sid(seq_list[index])\n",
    "    mod_pid = pid % max_pids\n",
    "    sid_list[mod_pid] = sid\n",
    "    \n",
    "    # Remove the first record from the list and write it to the file.\n",
    "    rec = seq_list.pop(index)\n",
    "    ofd.write(rec)\n",
    "    \n",
    "    # Loop until the list is empty.\n",
    "    while (len(seq_list) > 0):\n",
    "        # Get the next PID.\n",
    "        pid, sid, index = next_pid_in_list(seq_list, index, pid)\n",
    "        mod_pid = pid % max_pids\n",
    "        \n",
    "        # Try to get a new SID for this PID.\n",
    "        if (sid <= sid_list[mod_pid]):\n",
    "            pid, sid, index = next_sid_in_list(seq_list, index, pid, sid_list[mod_pid])\n",
    "        sid_list[mod_pid] = sid\n",
    "            \n",
    "        # Remove the record form the list and write it to the file.\n",
    "        rec = seq_list.pop(index)\n",
    "        ofd.write(rec)\n",
    "        \n",
    "        # This will happen if we pop the record at the very end of the list.\n",
    "        if (index >= len(seq_list)):\n",
    "            index = len(seq_list) - 1\n",
    "    \n",
    "    fu.close_file(ofd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de646f",
   "metadata": {},
   "source": [
    "#### Run this cell to create the ordered files for each sequence  \n",
    "Note that this can take a very long time to run (10+ minutes each for large files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a97e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: 2023-06-16 08:27:22 D:\\dev\\jupyter\\Icentia11k\\data\\p00\\sequences_p00000_p00099_AFIB.csv\n",
      "  1: 2023-06-16 08:27:54 Done.\n"
     ]
    }
   ],
   "source": [
    "start_index = 0  # Zero-based starting index into seq_file_list\n",
    "# num_files = len(seq_file_list)\n",
    "num_files = 1\n",
    "i = 0\n",
    "for i in range(start_index, start_index+num_files):\n",
    "    seq_file = seq_file_list[i]\n",
    "    print('{:3d}: {} {}'.format(i+1, ic.timestamp(), seq_file))\n",
    "    order_file(seq_file)\n",
    "print('{:3d}: {} Done.'.format(i+1, ic.timestamp()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00848ee",
   "metadata": {},
   "source": [
    "#### Check the files created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48354b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files: AFL: 109, AFIB: 110, N: 110, Q: 110\n",
      "Lines: AFL: 825775, AFIB: 2424476, N: 47187038, Q: 8208569\n"
     ]
    }
   ],
   "source": [
    "ordered_afl_file_pat = re.compile(r'ordered_p\\d{5}_p\\d{5}_AFL\\.csv')\n",
    "ordered_afib_file_pat = re.compile(r'ordered_p\\d{5}_p\\d{5}_AFIB\\.csv')\n",
    "ordered_n_file_pat = re.compile(r'ordered_p\\d{5}_p\\d{5}_N\\.csv')\n",
    "ordered_q_file_pat = re.compile(r'ordered_p\\d{5}_p\\d{5}_Q\\.csv')\n",
    "\n",
    "afib_file_count = 0\n",
    "afl_file_count = 0\n",
    "n_file_count = 0\n",
    "q_file_count = 0\n",
    "\n",
    "afib_line_count = 0\n",
    "afl_line_count = 0\n",
    "n_line_count = 0\n",
    "q_line_count = 0\n",
    "\n",
    "for sd in ic.SUBDIRS:\n",
    "    files = glob.glob(os.path.join(ic.LOCAL_DATA_PATH, sd, r'ordered_p*.csv'))\n",
    "    for file in files:\n",
    "        \n",
    "        if ordered_afl_file_pat.search(file):\n",
    "            afl_file_count += 1\n",
    "            sequences_file = os.path.join(dirpath, file)\n",
    "            with fu.open_file(sequences_file) as sfp:\n",
    "                for line in sfp:\n",
    "                    if (len(line.strip()) > 0):\n",
    "                        afl_line_count += 1\n",
    "            fu.close_file(sfp)\n",
    "            \n",
    "        elif ordered_afib_file_pat.search(file):\n",
    "            afib_file_count += 1\n",
    "            sequences_file = os.path.join(dirpath, file)\n",
    "            with fu.open_file(sequences_file) as sfp:\n",
    "                for line in sfp:\n",
    "                    if (len(line.strip()) > 0):\n",
    "                        afib_line_count += 1\n",
    "            fu.close_file(sfp)\n",
    "        \n",
    "        elif ordered_n_file_pat.search(file):\n",
    "            n_file_count += 1\n",
    "            sequences_file = os.path.join(dirpath, file)\n",
    "            with fu.open_file(sequences_file) as sfp:\n",
    "                for line in sfp:\n",
    "                    if (len(line.strip()) > 0):\n",
    "                        n_line_count += 1\n",
    "            fu.close_file(sfp)\n",
    "            \n",
    "        elif ordered_q_file_pat.search(file):\n",
    "            q_file_count += 1\n",
    "            sequences_file = os.path.join(dirpath, file)\n",
    "            with fu.open_file(sequences_file) as sfp:\n",
    "                for line in sfp:\n",
    "                    if (len(line.strip()) > 0):\n",
    "                        q_line_count += 1\n",
    "            fu.close_file(sfp)\n",
    "print('Files: AFL: {}, AFIB: {}, N: {}, Q: {}'.format(afl_file_count, afib_file_count, n_file_count, q_file_count))\n",
    "print('Lines: AFL: {}, AFIB: {}, N: {}, Q: {}'.format(afl_line_count, afib_line_count, n_line_count, q_line_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433372ca",
   "metadata": {},
   "source": [
    "### 3. Consolidate the individual ordered files into one file per rhythym type per subdirectory  \n",
    "Since AFL has the fewest sequences, we will construct it first and then build the others to match its size.  \n",
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c065a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a list of sequences from an open ordered rhythm sequence file.\n",
    "# Returns a set of sequences where each PID is unique in the set.\n",
    "# Returns an empty list when the file is exhausted.\n",
    "# Assumes that the PIDs are sorted in increasing order.\n",
    "def get_next_sequences_from_file(fd):\n",
    "    seq_list = []\n",
    "    curr_pid = 0\n",
    "    \n",
    "    # Get first sequence.\n",
    "    line = fd.readline()\n",
    "    if (len(line.strip()) > 0):\n",
    "        curr_pid, _ = get_pid_sid(line)\n",
    "        seq_list.append(line)\n",
    "    last_pid = curr_pid - 1  # Allow the loop to run at least once\n",
    "    \n",
    "    # Get remaining sequences.\n",
    "    while (curr_pid > last_pid):\n",
    "        last_pid = curr_pid\n",
    "        loc_in = fd.tell()\n",
    "        line = fd.readline()\n",
    "        if (len(line.strip()) > 0):\n",
    "            curr_pid, _ = get_pid_sid(line)\n",
    "            if (curr_pid > last_pid):\n",
    "                seq_list.append(line)\n",
    "            else:\n",
    "                fd.seek(loc_in)\n",
    "        else:\n",
    "            break  # End of file\n",
    "    return seq_list\n",
    "\n",
    "# Function to write a list of sequences to the ordered sequence file.\n",
    "# Stop when the maximum number is reached (if specified).\n",
    "# Returns the number of sequences written to the file.\n",
    "def write_sequences_to_file(fd, seq_list, seq_max=-1):\n",
    "    seq_count = 0\n",
    "    try:\n",
    "        for seq in seq_list:\n",
    "            if (seq_max >= 0):\n",
    "                if (seq_count < seq_max):\n",
    "                    fd.write(seq)\n",
    "                    seq_count += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                fd.write(seq)\n",
    "                seq_count += 1\n",
    "    except Exception as err:\n",
    "        print('File write error: {}'.format(str(err)))\n",
    "    return seq_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae0f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create one consolidated ordered file in the subdirectory for the rhythm type.\n",
    "# Ends when the number of sequences meets or exceeds seq_limit, or when all input files are exhausted.\n",
    "# Returns the number of sequences in the file.\n",
    "def create_ordered_subdir_file(sd, rtype, seq_limit=-1):    \n",
    "    seq_count = 0\n",
    "    ordered_fd_list = [None for i in range(10)]\n",
    "    ordered_file_pat = re.compile(r'ordered_p\\d{5}_p\\d{5}_' + rtype.upper() + r'\\.csv')\n",
    "    \n",
    "    subdir_path = os.path.join(ic.LOCAL_DATA_PATH, sd)\n",
    "    files = os.listdir(subdir_path)\n",
    "    \n",
    "    # Open the individual ordered rhythm files created in Step 2.\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        if ordered_file_pat.match(file):\n",
    "            ordered_fd_list[i] = fu.open_file(os.path.join(subdir_path, file))\n",
    "            i += 1\n",
    "    \n",
    "    try:\n",
    "        # Create the master ordered sequence file in this subdirectory for this rhythm type.\n",
    "        ordered_subdir_rtype_file_name = '{}_{}_{}.csv'.format(ic.ORDERED_SUBDIR_BN, sd, rtype)\n",
    "        ordered_subdir_rtype_file_path = os.path.join(subdir_path, ordered_subdir_rtype_file_name)\n",
    "        print('Creating {}'.format(ordered_subdir_rtype_file_path))\n",
    "        osrfd = fu.open_file(ordered_subdir_rtype_file_path, 'w')\n",
    "    \n",
    "        # Continuously loop through the individual ordered rhythm files until the end is reached.\n",
    "        # Get a set of sequences from each and write them to the master ordered sequence file.\n",
    "        seq_remain = True  # Allow loop to run at least once\n",
    "        while seq_remain:\n",
    "            seq_remain = False\n",
    "            for fd in ordered_fd_list:\n",
    "                if fd is not None:\n",
    "                    seq_list = get_next_sequences_from_file(fd)  # Get list of sequences\n",
    "                    seq_len = len(seq_list)\n",
    "                    if (seq_len > 0):\n",
    "                        # We have more sequences to write to the file.\n",
    "                        # See if we have a sequence limit.\n",
    "                        seq_max = -1\n",
    "                        if (seq_limit >= 0):  \n",
    "                            seq_max = max(seq_limit - seq_count, 0)\n",
    "                        seq_count += write_sequences_to_file(osrfd, seq_list, seq_max) # Write them to the file\n",
    "                        if (seq_limit >= 0):\n",
    "                            if (seq_count < seq_limit):\n",
    "                                seq_remain = True  # We did not hit our sequence limit\n",
    "                        else:\n",
    "                            seq_remain = True # No sequence limit in effect\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "    \n",
    "    # Close the master ordered sequence file.\n",
    "    fu.close_file(osrfd)\n",
    "\n",
    "    # Close the individual ordered rhythm files created in Step 2.\n",
    "    for fd in ordered_fd_list:\n",
    "        fu.close_file(fd)\n",
    "    return seq_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43930972",
   "metadata": {},
   "source": [
    "#### Construct one consolidated ordered rhythm type file per subdirectory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343ac7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdir: p00\n",
      "Creating E:/Data/Icentia11k/data\\p00\\ordered_dir_p00_AFL.csv\n",
      "AFL seq count: 56527\n",
      "Creating E:/Data/Icentia11k/data\\p00\\ordered_dir_p00_AFIB.csv\n",
      "AFIB seq count: 56527\n",
      "Creating E:/Data/Icentia11k/data\\p00\\ordered_dir_p00_N.csv\n",
      "N seq count: 56527\n",
      "Creating E:/Data/Icentia11k/data\\p00\\ordered_dir_p00_Q.csv\n",
      "Q seq count: 56527\n",
      "Subdir: p01\n",
      "Creating E:/Data/Icentia11k/data\\p01\\ordered_dir_p01_AFL.csv\n",
      "AFL seq count: 72977\n",
      "Creating E:/Data/Icentia11k/data\\p01\\ordered_dir_p01_AFIB.csv\n",
      "AFIB seq count: 72977\n",
      "Creating E:/Data/Icentia11k/data\\p01\\ordered_dir_p01_N.csv\n",
      "N seq count: 72977\n",
      "Creating E:/Data/Icentia11k/data\\p01\\ordered_dir_p01_Q.csv\n",
      "Q seq count: 72977\n",
      "Subdir: p02\n",
      "Creating E:/Data/Icentia11k/data\\p02\\ordered_dir_p02_AFL.csv\n",
      "AFL seq count: 76270\n",
      "Creating E:/Data/Icentia11k/data\\p02\\ordered_dir_p02_AFIB.csv\n",
      "AFIB seq count: 76270\n",
      "Creating E:/Data/Icentia11k/data\\p02\\ordered_dir_p02_N.csv\n",
      "N seq count: 76270\n",
      "Creating E:/Data/Icentia11k/data\\p02\\ordered_dir_p02_Q.csv\n",
      "Q seq count: 76270\n",
      "Subdir: p03\n",
      "Creating E:/Data/Icentia11k/data\\p03\\ordered_dir_p03_AFL.csv\n",
      "AFL seq count: 92249\n",
      "Creating E:/Data/Icentia11k/data\\p03\\ordered_dir_p03_AFIB.csv\n",
      "AFIB seq count: 92249\n",
      "Creating E:/Data/Icentia11k/data\\p03\\ordered_dir_p03_N.csv\n",
      "N seq count: 92249\n",
      "Creating E:/Data/Icentia11k/data\\p03\\ordered_dir_p03_Q.csv\n",
      "Q seq count: 92249\n",
      "Subdir: p04\n",
      "Creating E:/Data/Icentia11k/data\\p04\\ordered_dir_p04_AFL.csv\n",
      "AFL seq count: 111060\n",
      "Creating E:/Data/Icentia11k/data\\p04\\ordered_dir_p04_AFIB.csv\n",
      "AFIB seq count: 111060\n",
      "Creating E:/Data/Icentia11k/data\\p04\\ordered_dir_p04_N.csv\n",
      "N seq count: 111060\n",
      "Creating E:/Data/Icentia11k/data\\p04\\ordered_dir_p04_Q.csv\n",
      "Q seq count: 111060\n",
      "Subdir: p05\n",
      "Creating E:/Data/Icentia11k/data\\p05\\ordered_dir_p05_AFL.csv\n",
      "AFL seq count: 70821\n",
      "Creating E:/Data/Icentia11k/data\\p05\\ordered_dir_p05_AFIB.csv\n",
      "AFIB seq count: 70821\n",
      "Creating E:/Data/Icentia11k/data\\p05\\ordered_dir_p05_N.csv\n",
      "N seq count: 70821\n",
      "Creating E:/Data/Icentia11k/data\\p05\\ordered_dir_p05_Q.csv\n",
      "Q seq count: 70821\n",
      "Subdir: p06\n",
      "Creating E:/Data/Icentia11k/data\\p06\\ordered_dir_p06_AFL.csv\n",
      "Error closing file: 'NoneType' object has no attribute 'close'\n",
      "AFL seq count: 70487\n",
      "Creating E:/Data/Icentia11k/data\\p06\\ordered_dir_p06_AFIB.csv\n",
      "AFIB seq count: 70487\n",
      "Creating E:/Data/Icentia11k/data\\p06\\ordered_dir_p06_N.csv\n",
      "N seq count: 70487\n",
      "Creating E:/Data/Icentia11k/data\\p06\\ordered_dir_p06_Q.csv\n",
      "Q seq count: 70487\n",
      "Subdir: p07\n",
      "Creating E:/Data/Icentia11k/data\\p07\\ordered_dir_p07_AFL.csv\n",
      "AFL seq count: 60719\n",
      "Creating E:/Data/Icentia11k/data\\p07\\ordered_dir_p07_AFIB.csv\n",
      "AFIB seq count: 60719\n",
      "Creating E:/Data/Icentia11k/data\\p07\\ordered_dir_p07_N.csv\n",
      "N seq count: 60719\n",
      "Creating E:/Data/Icentia11k/data\\p07\\ordered_dir_p07_Q.csv\n",
      "Q seq count: 60719\n",
      "Subdir: p08\n",
      "Creating E:/Data/Icentia11k/data\\p08\\ordered_dir_p08_AFL.csv\n",
      "AFL seq count: 84699\n",
      "Creating E:/Data/Icentia11k/data\\p08\\ordered_dir_p08_AFIB.csv\n",
      "AFIB seq count: 84699\n",
      "Creating E:/Data/Icentia11k/data\\p08\\ordered_dir_p08_N.csv\n",
      "N seq count: 84699\n",
      "Creating E:/Data/Icentia11k/data\\p08\\ordered_dir_p08_Q.csv\n",
      "Q seq count: 84699\n",
      "Subdir: p09\n",
      "Creating E:/Data/Icentia11k/data\\p09\\ordered_dir_p09_AFL.csv\n",
      "AFL seq count: 62860\n",
      "Creating E:/Data/Icentia11k/data\\p09\\ordered_dir_p09_AFIB.csv\n",
      "AFIB seq count: 62860\n",
      "Creating E:/Data/Icentia11k/data\\p09\\ordered_dir_p09_N.csv\n",
      "N seq count: 62860\n",
      "Creating E:/Data/Icentia11k/data\\p09\\ordered_dir_p09_Q.csv\n",
      "Q seq count: 62860\n",
      "Subdir: p10\n",
      "Creating E:/Data/Icentia11k/data\\p10\\ordered_dir_p10_AFL.csv\n",
      "AFL seq count: 67106\n",
      "Creating E:/Data/Icentia11k/data\\p10\\ordered_dir_p10_AFIB.csv\n",
      "AFIB seq count: 67106\n",
      "Creating E:/Data/Icentia11k/data\\p10\\ordered_dir_p10_N.csv\n",
      "N seq count: 67106\n",
      "Creating E:/Data/Icentia11k/data\\p10\\ordered_dir_p10_Q.csv\n",
      "Q seq count: 67106\n"
     ]
    }
   ],
   "source": [
    "for sd in ic.SUBDIRS:\n",
    "    print('Subdir: {}'.format(sd))\n",
    "\n",
    "    # Construct the AFL file first and use its size to limit the others.\n",
    "    rtype = 'AFL'\n",
    "    afl_seq_count = create_ordered_subdir_file(sd, rtype)\n",
    "    print('{} seq count: {}'.format(rtype, afl_seq_count))\n",
    "\n",
    "    # Construct the remaining rhythm files.\n",
    "    for rtype in ['AFIB', 'N', 'Q']:\n",
    "        seq_count= create_ordered_subdir_file(sd, rtype, seq_limit=afl_seq_count)\n",
    "        print('{} seq count: {}'.format(rtype, seq_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b758616",
   "metadata": {},
   "source": [
    "### 4. Consolidate subdirectory files into one master ordered list per rhythm type  \n",
    "#### Functions  Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2587b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ordered_master_file(rtype):    \n",
    "    ordered_subdir_fd_list = [None for sd in ic.SUBDIRS]\n",
    "    ordered_master_file = '{}_{}.csv'.format(ic.ORDERED_MASTER_BN, rtype)\n",
    "    \n",
    "    # Open the subdir files for this rhythm type created in Step 3.\n",
    "    i = 0\n",
    "    for sd in ic.SUBDIRS:\n",
    "        filename = '{}_{}_{}.csv'.format(ic.ORDERED_SUBDIR_BN, sd, rtype.upper())\n",
    "        ordered_subdir_file = os.path.join(ic.LOCAL_DATA_PATH, sd, filename)\n",
    "        ordered_subdir_fd_list[i] = fu.open_file(os.path.join(ordered_subdir_file))\n",
    "        i += 1\n",
    "        \n",
    "    # Create the master file for this rhythm type.\n",
    "    print('Creating {}'.format(ordered_master_file))\n",
    "    omfd = fu.open_file(os.path.join(ic.LOCAL_DATA_PATH, ordered_master_file), 'w')\n",
    "     \n",
    "    try:\n",
    "        # Continuously loop through the individual ordered rhythm files until the end is reached.\n",
    "        # Get a set of sequences from each and write them to the master ordered sequence file.\n",
    "        seq_count = 0\n",
    "        seq_remain = True  # Allow loop to run at least once\n",
    "        while seq_remain:\n",
    "            seq_remain = False\n",
    "            for fd in ordered_subdir_fd_list:\n",
    "                if fd is not None:\n",
    "                    seq_list = get_next_sequences_from_file(fd)  # Get list of sequences\n",
    "                    seq_len = len(seq_list)\n",
    "                    if (seq_len > 0):\n",
    "                        # We have more sequences to write to the file.\n",
    "                        seq_count += write_sequences_to_file(omfd, seq_list)\n",
    "                        seq_remain = True\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "\n",
    "    # Close the master file.\n",
    "    fu.close_file(omfd)\n",
    "    \n",
    "    # Close the subdir files for this rhythm type created in Step 3.\n",
    "    for fd in ordered_subdir_fd_list:\n",
    "        fu.close_file(fd)\n",
    "    return seq_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ceaac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ordered_master_AFIB.csv\n",
      "AFIB count: 825775\n",
      "Creating ordered_master_AFL.csv\n",
      "AFL count: 825775\n",
      "Creating ordered_master_N.csv\n",
      "N count: 825775\n",
      "Creating ordered_master_Q.csv\n",
      "Q count: 825775\n"
     ]
    }
   ],
   "source": [
    "for rtype in ic.RTYPES:\n",
    "    seq_count = create_ordered_master_file(rtype)\n",
    "    print('{} count: {}'.format(rtype, seq_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851bca0",
   "metadata": {},
   "source": [
    "### 5. Analyze the master ordered lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b1f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a histogram of PIDs.\n",
    "def get_pid_histogram(file, seq_max=0):\n",
    "    seq_count = 0\n",
    "    pid_histo = np.zeros(ic.NUM_PATIENTS, dtype=np.int32)\n",
    "    with fu.open_file(file) as fd:\n",
    "        for line in fd:\n",
    "            if (len(line.strip()) > 0):\n",
    "                pid = int(line[1:6])\n",
    "                pid_histo[pid] += 1\n",
    "                if (seq_max > 0):\n",
    "                    seq_count += 1\n",
    "                    if (seq_count >= seq_max):\n",
    "                        break\n",
    "    fu.close_file(fd)\n",
    "    return pid_histo\n",
    "\n",
    "def analyze_file(rtype, seq_max=0):\n",
    "    master_file = '{}_{}.csv'.format(ic.ORDERED_MASTER_BN, rtype)\n",
    "    master_spec = os.path.join(ic.LOCAL_DATA_PATH, master_file)\n",
    "    histo = get_pid_histogram(master_spec, seq_max)\n",
    "    histo_sum, histo_cnt, histo_min, histo_avg, histo_max = ic.get_histo_stats(histo)\n",
    "    print('{:>4s}: Seq: {:6d} PIDs: {:5d}  min: {:3d}  avg: {:6.1f}  max: {:4d}'.format(\n",
    "        rtype, histo_sum, histo_cnt, histo_min, histo_avg, histo_max))\n",
    "    return histo_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e918fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFIB: Seq: 825775 PIDs:   727  min:   1  avg: 1135.9  max: 2186\n",
      " AFL: Seq: 825775 PIDs:   494  min:   1  avg: 1671.6  max: 6738\n",
      "   N: Seq: 825775 PIDs: 10258  min:   2  avg:   80.5  max:  120\n",
      "   Q: Seq: 825775 PIDs: 10849  min:   1  avg:   76.1  max:  125\n",
      "\n",
      "AFIB: Seq: 412887 PIDs:   727  min:   1  avg:  567.9  max:  689\n",
      " AFL: Seq: 412887 PIDs:   494  min:   1  avg:  835.8  max: 1700\n",
      "   N: Seq: 412887 PIDs: 10258  min:   2  avg:   40.3  max:   41\n",
      "   Q: Seq: 412887 PIDs: 10849  min:   1  avg:   38.1  max:   40\n",
      "\n",
      "AFIB: Seq: 206443 PIDs:   727  min:   1  avg:  284.0  max:  326\n",
      " AFL: Seq: 206443 PIDs:   493  min:   1  avg:  418.7  max:  675\n",
      "   N: Seq: 206443 PIDs: 10258  min:   2  avg:   20.1  max:   21\n",
      "   Q: Seq: 206443 PIDs: 10849  min:   1  avg:   19.0  max:   20\n",
      "\n",
      "AFIB: Seq: 103221 PIDs:   727  min:   1  avg:  142.0  max:  156\n",
      " AFL: Seq: 103221 PIDs:   493  min:   1  avg:  209.4  max:  288\n",
      "   N: Seq: 103221 PIDs: 10258  min:   2  avg:   10.1  max:   11\n",
      "   Q: Seq: 103221 PIDs: 10849  min:   1  avg:    9.5  max:   10\n",
      "\n",
      "AFIB: Seq:  51610 PIDs:   727  min:   1  avg:   71.0  max:   76\n",
      " AFL: Seq:  51610 PIDs:   493  min:   1  avg:  104.7  max:  129\n",
      "   N: Seq:  51610 PIDs: 10258  min:   2  avg:    5.0  max:    6\n",
      "   Q: Seq:  51610 PIDs: 10849  min:   1  avg:    4.8  max:    5\n",
      "\n",
      "AFIB: Seq:  25805 PIDs:   727  min:   1  avg:   35.5  max:   38\n",
      " AFL: Seq:  25805 PIDs:   493  min:   1  avg:   52.3  max:   61\n",
      "   N: Seq:  25805 PIDs: 10258  min:   2  avg:    2.5  max:    3\n",
      "   Q: Seq:  25805 PIDs: 10848  min:   1  avg:    2.4  max:    3\n",
      "\n",
      "AFIB: Seq:  12902 PIDs:   727  min:   1  avg:   17.7  max:   19\n",
      " AFL: Seq:  12902 PIDs:   493  min:   1  avg:   26.2  max:   29\n",
      "   N: Seq:  12902 PIDs: 10258  min:   1  avg:    1.3  max:    2\n",
      "   Q: Seq:  12902 PIDs: 10836  min:   1  avg:    1.2  max:    2\n"
     ]
    }
   ],
   "source": [
    "for rtype in ic.RTYPES:\n",
    "    seq = analyze_file(rtype)\n",
    "    \n",
    "while (seq > 20000):\n",
    "    seq = seq // 2\n",
    "    print()\n",
    "    for rtype in ic.RTYPES:\n",
    "        seq = analyze_file(rtype, seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34887f2d",
   "metadata": {},
   "source": [
    "### 6. Compare to the original rhythm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14377109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute and print the Patient ID stats for all original rhythm files.\n",
    "def get_rhythm_stats(desired_rtype):\n",
    "    num_patients = 11000\n",
    "    rhythms_file_pat = re.compile(ic.RHYTHMS_FILE_RE)\n",
    "    pid_histo = np.zeros(num_patients, dtype=np.int32)\n",
    "    \n",
    "    for sd in ic.SUBDIRS:\n",
    "        files = glob.glob(os.path.join(ic.LOCAL_DATA_PATH, sd, r'rhythms_p*.csv'))\n",
    "        for file in files:\n",
    "            if rhythms_file_pat.search(file):\n",
    "                with fu.open_file(file) as fd:\n",
    "                    for line in fd:\n",
    "                        parsed_line = line.strip().split(',')\n",
    "                        pid = int(parsed_line[0][1:])\n",
    "                        rtype = parsed_line[2]\n",
    "                        if (rtype == desired_rtype):\n",
    "                            pid_histo[pid] += 1\n",
    "                fu.close_file(fd)\n",
    "    histo_sum, histo_cnt, histo_min, histo_avg, histo_max = ic.get_histo_stats(pid_histo)\n",
    "    return (histo_sum, histo_cnt, histo_min, histo_avg, histo_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293e89f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFIB: Seq:   342816 PIDs:   728  min:   1  avg:  470.9  max: 1353\n",
      " AFL: Seq:   120621 PIDs:   494  min:   1  avg:  244.2  max: 1300\n",
      "   N: Seq:  6689763 PIDs: 10259  min:   1  avg:  652.1  max: 1318\n",
      "   Q: Seq:  2714781 PIDs: 10850  min:   1  avg:  250.2  max: 1158\n"
     ]
    }
   ],
   "source": [
    "for rtype in ic.RTYPES:\n",
    "    (histo_sum, histo_cnt, histo_min, histo_avg, histo_max) = get_rhythm_stats(rtype)\n",
    "    print('{:>4s}: Seq: {:8d} PIDs: {:5d}  min: {:3d}  avg: {:6.1f}  max: {:4d}'.format(\n",
    "        rtype, histo_sum, histo_cnt, histo_min, histo_avg, histo_max))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06b88b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
